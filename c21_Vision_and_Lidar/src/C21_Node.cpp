/**************************************************************************************
 * This is a basic prototype for the C21_vision_and_Lidar module for the robil project
 * The C21_vision_and_Lidar module goal is to provide a 3D reconstruction of a scene.
 *
 * this module generate a ROS node that provide the service on demand,
 * the reconstructed scene is represented by a point cloud, the point cloud can be viewed by the testing node
 *
 * due to lack of information on the robil structure and cameras
 * this prototype dosen'tmake use of the input specified in the capability document.
 *
 **************************************************************************************/

#include "ros/ros.h"
#include "c21_Vision_and_Lidar/C21.h"
#include <image_transport/image_transport.h>
#include <message_filters/synchronizer.h>
#include <message_filters/sync_policies/approximate_time.h>
#include <sensor_msgs/image_encodings.h>
#include <cv_bridge/cv_bridge.h>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv/cv.h>
#include <opencv/highgui.h>
#include <boost/thread/thread.hpp>
#include <boost/thread/mutex.hpp>
#include <boost/thread/locks.hpp>
#include <pcl/correspondence.h>
#include <pcl/point_cloud.h>
#include <pcl/common/common_headers.h>
#include <pcl/io/pcd_io.h>
#include <pcl/visualization/pcl_visualizer.h>
#include <image_transport/subscriber_filter.h>
#include <pcl_ros/point_cloud.h>

namespace enc=sensor_msgs::image_encodings;

/**
 * this class represent the C21_Node,
 * it subscribe to two camera/image topics and provide the 3D reconstruction service
 **/
class C21_Node{

public:

	/**
	 * constructor, initializes the ROS node, subscribe it to the given topics and instruct it to provide the service
	 * @param left_camera the left camera image topic
	 * @param right_camera the right camera image topic
	 */
	  C21_Node(std::string left_camera,std::string right_camera) :
		it_(nh_),
		//the purpose of the following 3 lines is to synchronize the data from the cameras using a message filter
		//more on filters and how to use them can be found on http://www.ros.org/wiki/message_filters
		left_image_sub_( it_, left_camera, 1 ),
		right_image_sub_( it_, right_camera, 1 ),
		sync( MySyncPolicy( 10 ), left_image_sub_, right_image_sub_ )
	  {
		ROS_INFO("finished subscribing\n");
		sync.registerCallback( boost::bind( &C21_Node::callback, this, _1, _2 ) );  //Specifying what to do with the data
		cv::FileStorage fs("Q.xml", cv::FileStorage::READ); // reading a Q matrix that tell us the stereo calibration
		fs["Q"] >> Q;

		  Q03 = Q.at<double>(0,3);
		  Q13 = Q.at<double>(1,3);
		  Q23 = Q.at<double>(2,3);
		  Q32 = Q.at<double>(3,2);
		  Q33 = Q.at<double>(3,3);
		_myMutex=new boost::mutex();
		service = nh_.advertiseService("C21", &C21_Node::proccess, this); //Specifying what to do when a reconstructed 3d scene is requested
		ROS_INFO("service on\n");
		cvStartWindowThread();
	  }


	  /**
	   * The call back function executed when a service is requested
	   * it must return true in order to work properly
	   * @param req the request message, generated by the node requesting the service
	   * @param res the response message, generated by the service node when a service is requested
	   */
	  bool proccess(c21_Vision_and_Lidar::C21::Request  &req,
			c21_Vision_and_Lidar::C21::Response &res )
	  {
		  ROS_INFO("recived request, tying to fetch data\n");

		  //reading the data we gathered
		   cv::Mat img_rgb = cv::imread("rgb.ppm", CV_LOAD_IMAGE_COLOR);
		   cv::Mat img_disparity = cv::imread("disp.ppm", CV_LOAD_IMAGE_GRAYSCALE);

		   //generating a point cloud
			 pcl::PointCloud<pcl::PointXYZRGB>::Ptr point_cloud_ptr (new pcl::PointCloud<pcl::PointXYZRGB>);

			 double px, py, pz;
			 uchar pr, pg, pb;

			 for (int i = 0; i < img_rgb.rows; i++)
			 {
			   uchar* rgb_ptr = img_rgb.ptr<uchar>(i);
			   uchar* disp_ptr = img_disparity.ptr<uchar>(i);
			   for (int j = 0; j < img_rgb.cols; j++)
			   {
				 //Get 3D coordinates
				 uchar d = disp_ptr[j];
				 if ( d == 0 ) continue; //Discard bad pixels
				 double pw = -1.0 * static_cast<double>(d) * Q32 + Q33;
				 px = static_cast<double>(j) + Q03;
				 py = static_cast<double>(i) + Q13;
				 pz = Q23;

				 px = px/pw;
				 py = py/pw;
				 pz = pz/pw;

				 //Get RGB info
				 pb = rgb_ptr[3*j];
				 pg = rgb_ptr[3*j+1];
				 pr = rgb_ptr[3*j+2];

				 //Insert info into point cloud structure
				 pcl::PointXYZRGB point;
				 point.x = px;
				 point.y = py;
				 point.z = pz;
				 uint32_t rgb = (static_cast<uint32_t>(pr) << 16 |
						 static_cast<uint32_t>(pg) << 8 | static_cast<uint32_t>(pb));
				 point.rgb = *reinterpret_cast<float*>(&rgb);
				 point_cloud_ptr->points.push_back (point);
			   }
			 }
			 point_cloud_ptr->width = (int) point_cloud_ptr->points.size();
			 point_cloud_ptr->height = 1;

			 //converting the point cloud to a ROS message and saving it the response object
			 pcl::PointCloud<pcl::PointXYZRGB> ans(*point_cloud_ptr);
			 pcl::toROSMsg<pcl::PointXYZRGB>(ans,res.scene_full_resolution_msg.cloud);

		  return true;
	  }


	  /**
	   * The call back function executed when a data is available
	   * @param left_msg ROS mesage with image data from the left camera topic
	   * @param right_msg ROS mesage with image data from the right camera topic
	   */
	  void callback(const sensor_msgs::ImageConstPtr& left_msg,const sensor_msgs::ImageConstPtr& right_msg){
		 cv_bridge::CvImagePtr left;
		 cv_bridge::CvImagePtr right;

		try
		{
		  left = cv_bridge::toCvCopy(left_msg,enc::RGB8);
		  right =cv_bridge::toCvCopy(right_msg,enc::RGB8);
		}
		catch (cv_bridge::Exception& e)
		{
		  ROS_ERROR("cv_bridge exception: %s", e.what());
		  return;
		}
		IplImage tosave=left->image;
		cvSaveImage("rgb.ppm",&tosave);

		//calculating disparity
		cv::Mat left_image;
		cv::Mat right_image;
		cv::cvtColor( left->image,left_image, CV_BGR2GRAY);
		cv::cvtColor( right->image,right_image,CV_BGR2GRAY);
		IplImage temp=left_image;
		IplImage temp2=right_image;
		CvMat *matf= cvCreateMat ( temp.height, temp.width, CV_16S);
		CvStereoBMState * state=cvCreateStereoBMState(CV_STEREO_BM_BASIC,64);
		cvFindStereoCorrespondenceBM(&temp,&temp2,matf,state);
		CvMat * disp_left_visual= cvCreateMat(temp.height, temp.width, CV_8U);
		cvConvertScale( matf, disp_left_visual, -16 );
		cvNormalize( matf, matf, 0, 256, CV_MINMAX, NULL );
		int i, j;
		uchar *ptr_dst;
		IplImage *cv_image_depth_aux = cvCreateImage (cvGetSize(&temp),IPL_DEPTH_8U, 3);
		for ( i = 0; i < matf->rows; i++)
		{
			ptr_dst = (uchar*)(cv_image_depth_aux->imageData + i*cv_image_depth_aux->widthStep);
			for ( j = 0; j < matf->cols; j++ )
			{
				ptr_dst[3*j] = (uchar)((short int*)(matf->data.ptr + matf->step*i))[j];
				ptr_dst[3*j+1] = (uchar)((short int*)(matf->data.ptr + matf->step*i))[j];
				ptr_dst[3*j+2] = (uchar)((short int*)(matf->data.ptr + matf->step*i))[j];
			}
		}

		cvSaveImage("disp.ppm",cv_image_depth_aux);
		cvReleaseMat(&matf);
		cvReleaseStereoBMState(&state);
		cvReleaseMat(&disp_left_visual);
		cvReleaseImage(&cv_image_depth_aux);
	  }

private:
  ros::NodeHandle nh_;
  image_transport::ImageTransport it_;
  cv::Mat Q;
  int counter;
  bool request;
  boost::mutex * _myMutex;
  typedef image_transport::SubscriberFilter ImageSubscriber;
  pcl::PointCloud<pcl::PointXYZRGB>* my_answer;

  ImageSubscriber left_image_sub_;
  ImageSubscriber right_image_sub_;
  ros::ServiceServer service;
  typedef message_filters::sync_policies::ApproximateTime<
    sensor_msgs::Image, sensor_msgs::Image
  > MySyncPolicy;
  double Q03, Q13, Q23, Q32, Q33;
  message_filters::Synchronizer< MySyncPolicy > sync;
};

int main(int argc, char **argv)
{
  ros::init(argc, argv, "c21_Vision_and_Lidar");
  if(argc!=3){
	  printf("usage: C21_module <left camera topic> <right camera topic>");
  }
  C21_Node my_node(argv[1],argv[2]);
  ROS_INFO("made topic at %s %s \n",argv[1],argv[2]);
  while(ros::ok()){
	  ros::spin();
  }
  return 0;
}

