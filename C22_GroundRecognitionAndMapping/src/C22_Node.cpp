/**************************************************************************************
 * This is a template for the C22_GroundRecognitionAndMapping module for the robil project
 * The C22_GroundRecognitionAndMapping module goal is to provide a mapping of the terrain that surrounds the robot
 * The mapping include the planes that reside on each square 0.25 meter and their coefficients
 **************************************************************************************/

#include "ros/ros.h"
#include "pclPlane.h"
#include "MPlane.h"
#include "MapMatrix.h"
#include "C22_GroundRecognitionAndMapping/C22.h"
#include "C22_GroundRecognitionAndMapping/C22C24.h"
#include <C21_VisionAndLidar/C21_C22.h>
#include "sensor_msgs/PointCloud.h"
#include <pcl/correspondence.h>
#include <pcl/point_cloud.h>
#include <pcl/common/common_headers.h>
#include <pcl/visualization/pcl_visualizer.h>
#include <pcl/io/pcd_io.h>
#include <pcl_ros/point_cloud.h>
#include <pcl/ModelCoefficients.h>
#include <pcl/point_types.h>
#include <pcl/filters/extract_indices.h>
#include <pcl/filters/voxel_grid.h>
#include <pcl/filters/statistical_outlier_removal.h>
#include <pcl/segmentation/sac_segmentation.h>
#include <iostream>
#include <pcl/io/pcd_io.h>
#include <iostream>
#include <boost/thread/thread.hpp>
#include <boost/bind.hpp>
#include <pcl/sample_consensus/sac_model_plane.h>
#include "C22_Node.h"
#include <tf/tf.h>
#include <pcl_ros/transforms.h>
#include <message_filters/subscriber.h>
#include <message_filters/synchronizer.h>
#include <message_filters/time_synchronizer.h>
#include <message_filters/sync_policies/approximate_time.h>
#include "std_srvs/Empty.h"
//c24 added includes
#include <nav_msgs/Odometry.h>
#include <sensor_msgs/Imu.h>
#include <tf/transform_datatypes.h>
#include <tf/LinearMath/Matrix3x3.h>
#include <boost/thread/mutex.hpp>
/**
 * this class represent the C22_Node,
 * it subscribe to the drc multisense topic and provide the Eagle eye mapping
 **/

boost::mutex m;
C22_Node::C22_Node():
	pointCloud_sub(nh_,"/C21/C22",1),
	pos_sub(nh_,"/ground_truth_odom",1),
	sync( MySyncPolicy( 10 ),pointCloud_sub, pos_sub){
	sync.registerCallback( boost::bind( &C22_Node::callback, this, _1, _2) );
	_myMatrix=new MapMatrix();
	_myPlanes=new std::vector<pclPlane*>();
	ROS_INFO("C22 Online\n");
	C22_pub=nh2_.advertise<C22_GroundRecognitionAndMapping::C22C0_PATH>("C22_pub",1);
	//test1=nh_.subscribe("/C21/C22",1,&C22_Node::callback2,this);
	//test2=nh_.subscribe("/ground_truth_odom",1,&C22_Node::callback3,this);
	service = nh2_.advertiseService("C22", &C22_Node::proccess, this); //Specifying what to do when a reconstructed 3d scene is requested
	service2 = nh2_.advertiseService("C22/C24", &C22_Node::proccess2, this); //Specifying what to do when a reconstructed 3d scene is requested

}

/**
 * The call back function executed when a service is requested
 * it must return true in order to work properly
 * @param req the request message, generated by the node requesting the service
 * @param res the response message, generated by the service node when a service is requested
 */
bool C22_Node::proccess(C22_GroundRecognitionAndMapping::C22::Request  &req,
	C22_GroundRecognitionAndMapping::C22::Response &res ){
	//ROS_INFO("received request, trying to fetch data\n");
	res.drivingPath.row.resize(_myMatrix->data->size());
	res.drivingPath.robotPos.x=robotPos.x;
	res.drivingPath.robotPos.y=robotPos.y;
	res.drivingPath.robotPos.z=robotPos.z;
	res.drivingPath.robotOri.x=robotOri.x;
	res.drivingPath.robotOri.y=robotOri.y;
	res.drivingPath.robotOri.z=robotOri.z;
	boost::mutex::scoped_lock l(_myMatrix->mutex);
	res.drivingPath.xOffset=_myMatrix->xOffset;
	res.drivingPath.yOffset=_myMatrix->yOffset;
	for(unsigned int i=0;i<_myMatrix->data->size();i++){
		res.drivingPath.row.at(i).column.resize(_myMatrix->data->at(i)->size());
		for(unsigned int j=0;j<_myMatrix->data->at(i)->size();j++){
			res.drivingPath.row.at(i).column.at(j).status=_myMatrix->data->at(i)->at(j)->square_status;
			res.drivingPath.row.at(i).column.at(j).planes.resize(_myMatrix->data->at(i)->at(j)->square_Planes->size());
			for(unsigned int k=0;k<_myMatrix->data->at(i)->at(j)->square_Planes->size();k++){
				res.drivingPath.row.at(i).column.at(j).planes.at(k).x=_myMatrix->data->at(i)->at(j)->square_Planes->at(k)->coefficient_x;
				res.drivingPath.row.at(i).column.at(j).planes.at(k).y=_myMatrix->data->at(i)->at(j)->square_Planes->at(k)->coefficient_y;
				res.drivingPath.row.at(i).column.at(j).planes.at(k).z=_myMatrix->data->at(i)->at(j)->square_Planes->at(k)->coefficient_z;
				res.drivingPath.row.at(i).column.at(j).planes.at(k).d=_myMatrix->data->at(i)->at(j)->square_Planes->at(k)->coefficient_d;
			}
		}
	}
  return true;
}


/**
 * The call back function executed when a service is requested
 * it must return true in order to work properly
 * @param req the request message, generated by the node requesting the service
 * @param res the response message, generated by the service node when a service is requested
 */
bool C22_Node::proccess2(C22_GroundRecognitionAndMapping::C22C24::Request  &req,
	C22_GroundRecognitionAndMapping::C22C24::Response &res ){
	ROS_INFO("received request, tying to fetch data\n");
	res.drivingPath.row.resize(_myMatrix->data->size());
	for(unsigned int i=0;i<_myMatrix->data->size();i++){
		res.drivingPath.row. at(i).column.resize(_myMatrix->data->at(i)->size());
		for(unsigned int j=0;j<_myMatrix->data->at(i)->size();j++){
			res.drivingPath.row.at(i).column.at(j).status=_myMatrix->data->at(i)->at(j)->square_status;
			res.drivingPath.row.at(i).column.at(j).height=-1000;
			for(unsigned int k=0;k<_myMatrix->data->at(i)->at(j)->square_Planes->size();k++){
				res.drivingPath.row.at(i).column.at(j).height=std::max(res.drivingPath.row.at(i).column.at(j).height,_myMatrix->data->at(i)->at(j)->square_Planes->at(k)->representing_point.y);
			}
		}
	}
  return true;
}

/**
 * The call back function executed when a new point cloud has arrived
 */
void C22_Node::callback(const C21_VisionAndLidar::C21_C22::ConstPtr& pclMsg,const nav_msgs::Odometry::ConstPtr& pos_msg){

	 pcl::PointCloud<pcl::PointXYZ>cloud;
	 pcl::fromROSMsg<pcl::PointXYZ>(pclMsg->cloud,cloud);
	 pcl::PointCloud<pcl::PointXYZ>::Ptr cloud_filtered(cloud.makeShared());


	 tf::Transform trans;
	 trans.setOrigin(tf::Vector3(pclMsg->pose.position.x,pclMsg->pose.position.y,pclMsg->pose.position.z));
	 trans.setRotation(tf::Quaternion(pclMsg->pose.orientation.x,pclMsg->pose.orientation.y,pclMsg->pose.orientation.z,pclMsg->pose.orientation.w));
	 tf::Transform trans2;
	 	 trans2.setOrigin(tf::Vector3(pos_msg->pose.pose.position.x,pos_msg->pose.pose.position.y,pos_msg->pose.pose.position.z));
	 	 trans2.setRotation(tf::Quaternion(pos_msg->pose.pose.orientation.x,pos_msg->pose.pose.orientation.y,pos_msg->pose.pose.orientation.z,pos_msg->pose.pose.orientation.w));
	 	/*tf::Transform trans3;
	 	 trans3.setOrigin(tf::Vector3(0.0,-0.002, 0.035 ));
	 	 trans3.setRotation(tf::Quaternion(-1.57,3.14,1.57));*/
	 Eigen::Matrix4f sensorToHead,headTopelvis,pelvisToWorld;
	 //pcl_ros::transformAsMatrix(trans3, sensorToHead);
     //pcl_ros::transformAsMatrix(trans, headTopelvis);
	 pcl_ros::transformAsMatrix(trans2, pelvisToWorld);

	 tf::Quaternion q;
	 double roll, pitch, yaw;
	 tf::quaternionMsgToTF(pos_msg->pose.pose.orientation, q);
	 tf::Matrix3x3(q).getRPY(roll, pitch, yaw);
	 tf::Quaternion myEuler(pos_msg->pose.pose.orientation.x,pos_msg->pose.pose.orientation.y,pos_msg->pose.pose.orientation.z,pos_msg->pose.pose.orientation.w);
	 robotPos.x=pos_msg->pose.pose.position.x;
	 robotPos.y=pos_msg->pose.pose.position.y;
	 robotPos.z=pos_msg->pose.pose.position.z;
	 robotOri.x=roll;
	 robotOri.y=pitch;
	 robotOri.z=yaw;
	 // transform pointcloud from sensor frame to fixed robot frame
	 //pcl::transformPointCloud(*cloud_filtered, *cloud_filtered, sensorToHead);
	 //pcl::transformPointCloud(*cloud_filtered, *cloud_filtered, headTopelvis);
	 pcl::transformPointCloud(*cloud_filtered, *cloud_filtered, pelvisToWorld);

	 //transform the point cloud (mirror image)
	 for (unsigned int i=0;i<cloud_filtered->size();i++){
		 cloud_filtered->at(i).y=-cloud_filtered->at(i).y;
	 }


		_myMatrix->updateMapRelationToWorld(pos_msg->pose.pose.position.x,pos_msg->pose.pose.position.y);
		_myMatrix->computeMMatrix(cloud_filtered,robotPos);

			  cloud_filtered.reset();

	  C22_GroundRecognitionAndMapping::C22C0_PATH outMsg;
	  outMsg.row.resize(_myMatrix->data->size());
	  outMsg.robotPos.x=robotPos.x;
	  outMsg.robotPos.y=robotPos.y;
	  outMsg.robotPos.z=robotPos.z;
	  outMsg.robotOri.x=robotOri.x;
	  outMsg.robotOri.y=robotOri.y;
	  outMsg.robotOri.z=robotOri.z;
			  	boost::mutex::scoped_lock l(_myMatrix->mutex);
			  	outMsg.xOffset=_myMatrix->xOffset;
			  	outMsg.yOffset=_myMatrix->yOffset;
			  	for(unsigned int i=0;i<_myMatrix->data->size();i++){
			  		outMsg.row.at(i).column.resize(_myMatrix->data->at(i)->size());
			  		for(unsigned int j=0;j<_myMatrix->data->at(i)->size();j++){
			  			outMsg.row.at(i).column.at(j).status=_myMatrix->data->at(i)->at(j)->square_status;
			  			outMsg.row.at(i).column.at(j).planes.resize(_myMatrix->data->at(i)->at(j)->square_Planes->size());
			  			for(unsigned int k=0;k<_myMatrix->data->at(i)->at(j)->square_Planes->size();k++){
			  				outMsg.row.at(i).column.at(j).planes.at(k).x=_myMatrix->data->at(i)->at(j)->square_Planes->at(k)->coefficient_x;
			  				outMsg.row.at(i).column.at(j).planes.at(k).y=_myMatrix->data->at(i)->at(j)->square_Planes->at(k)->coefficient_y;
			  				outMsg.row.at(i).column.at(j).planes.at(k).z=_myMatrix->data->at(i)->at(j)->square_Planes->at(k)->coefficient_z;
			  				outMsg.row.at(i).column.at(j).planes.at(k).d=_myMatrix->data->at(i)->at(j)->square_Planes->at(k)->coefficient_d;
			  			}
			  		}
			  	}
	//_myMatrix->setAtlasPos(robotPos);
	  C22_pub.publish(outMsg);
}

C22_Node *node22;
int main(int argc, char **argv)
{
  ros::init(argc, argv, "c22_groundReconition_and_mapping");
  node22=new C22_Node();
  ros::AsyncSpinner spinner(4); // Use 4 threads
  spinner.start();
  ros::waitForShutdown();
  return 0;
}
