<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<task_description>
    <task name="DismountVechicleInit">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C51 - return the robot to initial position so it can exit</algorithm>
    </task>
    <task name="MountVehicle">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C46 - mounts the robot onto the car from a given posture (yet to be defined)</algorithm>
    </task>
    <task name="GripSteeringWheel">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C52 - Robot is sitting in vehicle, grip wheel</algorithm>
    </task>
    <task name="ObjectAttachment">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C66 Attach object A to B</algorithm>
    </task>
    <task name="AlignObjects">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C66 Align objects A and B</algorithm>
    </task>
    <task name="DismountVechicle">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C47</algorithm>
    </task>
    <task name="HMIResponce">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C11 receives data from OCU (TCP/UDP/ROS whatever chosen) and updates the relevant tasks</algorithm>
    </task>
    <task name="PostureControl">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C45 given a pose it executes it // TODO: FIX TREE FOR CORRECT PARAMETER</algorithm>
    </task>
    <task name="SearchObjectsFromInside">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm/>
    </task>
    <task name="Stop">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C47 scripted motion</algorithm>
    </task>
    <task name="MountVehicleInit">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C45 - need to sync with C46 requirements for mounting on the vehicle</algorithm>
    </task>
    <task name="WayPointsDriving">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C51 - way point driver, asks path from C31 and drives according to it</algorithm>
    </task>
    <task name="PathPlanning">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C31 calculates paths on occupancy grids, fails when it's no longer possible to do so</algorithm>
    </task>
    <task name="PlaceFeetOnPedals">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C52 - move the foots to be on the pedals</algorithm>
    </task>
    <task name="Squat">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C47 scripted motion</algorithm>
    </task>
    <task name="FollowPath">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C42 retrieves a path from the path planner and moves the robot along that path</algorithm>
    </task>
    <task name="Monitor">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>Wait for specified target event
   target=Falling: C35 returns when robot has fallen
   target=LiveLock: C35 returns if a live lock is found
   target=Stable: 35 returns when the robot is not stable
   target=Timeout: C35 returns if the subtree execution is taking too long</algorithm>
    </task>
    <task name="PathPlanningFocus">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C31 Path planner should set the planning for target A</algorithm>
    </task>
    <task name="LocalizationTrack">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C25 tracks robot position in 3D environment, fails when it's no longer possible to do so (not when localization is bad)</algorithm>
    </task>
    <task name="StandUp">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C47 scripted motion</algorithm>
    </task>
    <task name="ReturnToEntryPosture">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C45 - return the robot to the start position
</algorithm>
    </task>
    <task name="TestSteering">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C51 - Robot in vehicle, test steering</algorithm>
    </task>
    <task name="InitDrive">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C52 - test that the shift is neutral/forward (preconditions of WayPointsDriving), and that the driving can begin</algorithm>
    </task>
    <task name="TurnTo">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C41 it gets the locations of A from the perception services and turns towards it

parameters:
target=Doorway
selfPosition=internal,external</algorithm>
    </task>
    <task name="ReverseAttachment">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C66 reverse the attachment and return hands to start position (with object in hand)</algorithm>
    </task>
    <task name="X1">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm/>
    </task>
    <task name="TestPedals">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C51 - move foot to pedals</algorithm>
    </task>
    <task name="TrackObject">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C23 Tracks object A position withing the image, fails if there is no longer a method to predict it</algorithm>
    </task>
    <task name="PickUp">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C66 pick up an object (without walking)</algorithm>
    </task>
    <task name="whileObjectInHands">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C66 returns if there is no more an object in one of the hands</algorithm>
    </task>
    <task name="ObstacleDetection">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C24 detects obstacles in 3D, fails when it's no longer possible to detect objects </algorithm>
    </task>
    <task name="LookAt">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C</algorithm>
    </task>
    <task name="isObjectInHand">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C66 returns if there is an object in one of the hands</algorithm>
    </task>
    <task name="PushHMI">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>data=occupancy_grid - C11 it retrieves the occupancy grid and sends it back to the operator
data=panoramic_image - C11 it retrieves the panoramic image and sends it back to the operator
data=path - C11 it retrieves the path and sends it back to the operator</algorithm>
    </task>
    <task name="SearchObject">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C24 Actually moves the robot until the object is visible</algorithm>
    </task>
    <task name="ReturnToExitPosture">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C51 - return the robot to initial position so it can exit</algorithm>
    </task>
    <task name="HMIResponse">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C11 receives data from OCU (TCP/UDP/ROS whatever chosen) and updates the relevant tasks</algorithm>
    </task>
    <task name="FinishDrive">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm>C52 - finish the driving rutine</algorithm>
    </task>
    <task name="OperatorCheckPoint">
        <conditions/>
        <constraints/>
        <effects/>
        <algorithm/>
    </task>
</task_description>
