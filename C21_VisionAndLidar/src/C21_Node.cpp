/**************************************************************************************
 * This is a basic prototype for the C21_vision_and_Lidar module for the robil project
 * The C21_vision_and_Lidar module goal is to provide a 3D reconstruction of a scene.
 **************************************************************************************/

#include "ros/ros.h"
#include "C21_VisionAndLidar/C21.h"
#include "C21_VisionAndLidar/C21_Pan.h"
#include "C21_VisionAndLidar/C21_Pic.h"
#include <image_transport/image_transport.h>
#include <message_filters/synchronizer.h>
#include <message_filters/subscriber.h>
#include <message_filters/sync_policies/approximate_time.h>
#include <sensor_msgs/image_encodings.h>
#include <cv_bridge/cv_bridge.h>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv/cv.h>
#include <opencv/highgui.h>
#include <boost/thread/thread.hpp>
#include <boost/thread/mutex.hpp>
#include <boost/thread/locks.hpp>
#include <pcl/correspondence.h>
#include <pcl/point_cloud.h>
#include <pcl/common/common_headers.h>
#include <pcl/io/pcd_io.h>
#include <pcl/visualization/pcl_visualizer.h>
#include <image_transport/subscriber_filter.h>
#include <pcl_ros/point_cloud.h>
#include "opencv2/stitching/stitcher.hpp"
#include "std_msgs/Empty.h"
namespace enc=sensor_msgs::image_encodings;

/**
 * this class represent the C21_Node,
 * it subscribe to two camera/image topics and provide the 3D reconstruction service
 **/
class C21_Node{

public:

	/**
	 * constructor, initializes the ROS node, subscribe it to the given topics and instruct it to provide the service
	 * @param left_camera the left camera image topic
	 * @param right_camera the right camera image topic
	 */
	  C21_Node(std::string left_camera,std::string right_camera) :
		it_(nh_),
		//the purpose of the following 3 lines is to synchronize the data from the cameras using a message filter
		//more on filters and how to use them can be found on http://www.ros.org/wiki/message_filters
		left_image_sub_( it_, left_camera, 1 ),
		right_image_sub_( it_, right_camera, 1 ),
		pointcloud(nh_,"/multisense_sl/camera/points2",1),
		sync( MySyncPolicy( 10 ), left_image_sub_, right_image_sub_ ,pointcloud)
	  {
		leftpub = it_.advertise("C21/left_camera/image", 1);
		rightpub = it_.advertise("C21/right_camera/image", 1);
		//set compression data to png
		ROS_INFO("finished subscribing\n");
		sync.registerCallback( boost::bind( &C21_Node::callback, this, _1, _2,_3 ) );  //Specifying what to do with the data
		_panMutex=new boost::mutex();
		_cloudMutex=new boost::mutex();
		pcl_service = nh_.advertiseService("C21", &C21_Node::proccess, this); //Specifying what to do when a reconstructed 3d scene is requested
		pano_service = nh_.advertiseService("C21/Panorama", &C21_Node::pano_proccess, this);
		pic_service= nh_.advertiseService("C21/Pic", &C21_Node::pic_proccess, this);
		pan_imgs=new std::vector<cv::Mat>();
		ROS_INFO("service on\n");
		//boost::thread panorama(&C21_Node::publishPanorama,this);
	  }


	  /**
	   * The call back function executed when a service is requested
	   * it must return true in order to work properly
	   * @param req the request message, generated by the node requesting the service
	   * @param res the response message, generated by the service node when a service is requested
	   */
	  bool proccess(C21_VisionAndLidar::C21::Request  &req,
			C21_VisionAndLidar::C21::Response &res )
	  {
		  ROS_INFO("recived request, tying to fetch data\n");
		  _cloudMutex->lock();
		  pcl::toROSMsg(my_answer,res.scene_full_resolution_msg.cloud);
		  _cloudMutex->unlock();
		  return true;
	  }

	  bool pic_proccess(C21_VisionAndLidar::C21_Pic::Request  &req,
	  			  C21_VisionAndLidar::C21_Pic::Response &res )
	  	  {
		  	  _panMutex->lock();
	  			cv_bridge::CvImage cvi;
			    cvi.header.stamp = ros::Time::now();
			    cvi.header.frame_id = "image";
			    cvi.encoding = "rgb8";
			    if(req.req.cmd==C21_VisionAndLidar::C21_PICTURE::LEFT){
			    	cvi.image = leftImage;
			    }else{
			    	cvi.image = rightImage;
			    }
			    cvi.toImageMsg(res.res);
	  	      _panMutex->unlock();

	  		  return true;
	  	  }



	  bool pano_proccess(C21_VisionAndLidar::C21_Pan::Request  &req,
			  C21_VisionAndLidar::C21_Pan::Response &res )
	  {

		  if(req.req.cmd==C21_VisionAndLidar::C21_PANORAMA::TAKE_PICTURE){
			  _panMutex->lock();
			  cv::Mat im;
			  leftImage.copyTo(im);
			  pan_imgs->push_back(im);
			  _panMutex->unlock();
		  }else{
			  if(pan_imgs->size()==0)
				  return false;
			  cv::Mat pano;
			  cv::Stitcher stitcher = cv::Stitcher::createDefault(false);
			  stitcher.stitch(*pan_imgs, pano);
			  cv_bridge::CvImage cvi;
			  cvi.header.stamp = ros::Time::now();
			  cvi.header.frame_id = "image";
			  cvi.encoding = "rgb8";
			  cvi.image = pano;
			  cvi.toImageMsg(res.res);
			  while(pan_imgs->size()>0){
				  cv::Mat im=pan_imgs->back();
				  pan_imgs->pop_back();
				  im.release();
			  }


		  }
		  return true;
	  }

	  /**
	   * The call back function executed when a data is available
	   * @param left_msg ROS mesage with image data from the left camera topic
	   * @param right_msg ROS mesage with image data from the right camera topic
	   */
	  void callback(const sensor_msgs::ImageConstPtr& left_msg,const sensor_msgs::ImageConstPtr& right_msg,const sensor_msgs::PointCloud2::ConstPtr &cloud){
		 cv_bridge::CvImagePtr left;
		 cv_bridge::CvImagePtr right;
		try
		{
		  left = cv_bridge::toCvCopy(left_msg,enc::RGB8);
		  right =cv_bridge::toCvCopy(right_msg,enc::RGB8);
		}
		catch (cv_bridge::Exception& e)
		{
		  ROS_ERROR("cv_bridge exception: %s", e.what());
		  return;
		}
		//left_msg->header.stamp=ros::Time::now();
		//right_msg->header.stamp=ros::Time::now();
		leftpub.publish(left_msg);
		rightpub.publish(right_msg);
		/*
		 *saving frames for HMI use
		 */
		_panMutex->lock();
		left->image.copyTo(leftImage);
		right->image.copyTo(rightImage);
		_panMutex->unlock();
		pcl::PointCloud<pcl::PointXYZ> out;
		pcl::fromROSMsg(*cloud,out);
		_cloudMutex->lock();
		my_answer.swap(out);
		//pcl::io::savePCDFile("cloud.pcd",out,true);
		_cloudMutex->unlock();

	  }

private:
  ros::NodeHandle nh_;
  image_transport::ImageTransport it_;
  cv::Mat Q;
  int counter;
  bool request;
  boost::mutex * _panMutex;
  boost::mutex * _cloudMutex;
  typedef image_transport::SubscriberFilter ImageSubscriber;
  pcl::PointCloud<pcl::PointXYZ> my_answer;
  cv::Mat leftImage;
  cv::Mat rightImage;
  ImageSubscriber left_image_sub_;
  ImageSubscriber right_image_sub_;
  image_transport::Publisher leftpub;
  image_transport::Publisher rightpub;
  image_transport::Publisher smallPanoramicPublisher;
  message_filters::Subscriber<sensor_msgs::PointCloud2> pointcloud;

  ros::ServiceServer pcl_service;

  std::vector<cv::Mat> *pan_imgs;
  ros::ServiceServer pano_service;
  ros::ServiceServer pic_service;

  typedef message_filters::sync_policies::ApproximateTime<
    sensor_msgs::Image, sensor_msgs::Image,sensor_msgs::PointCloud2
  > MySyncPolicy;
  message_filters::Synchronizer< MySyncPolicy > sync;
};

int main(int argc, char **argv)
{
  ros::init(argc, argv, "C21_VisionAndLidar");
  C21_Node my_node("/multisense_sl/camera/left/image_raw","/multisense_sl/camera/right/image_raw");
  while(ros::ok()){
	  ros::spin();
  }
  return 0;
}

