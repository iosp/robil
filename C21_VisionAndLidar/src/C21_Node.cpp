/**************************************************************************************
 * This is a basic prototype for the C21_vision_and_Lidar module for the robil project
 * The C21_vision_and_Lidar module goal is to provide a 3D reconstruction of a scene.
 **************************************************************************************/

#include "ros/ros.h"
#include "C21_VisionAndLidar/C21.h"
#include <image_transport/image_transport.h>
#include <message_filters/synchronizer.h>
#include <message_filters/sync_policies/approximate_time.h>
#include <sensor_msgs/image_encodings.h>
#include <cv_bridge/cv_bridge.h>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv/cv.h>
#include <opencv/highgui.h>
#include <boost/thread/thread.hpp>
#include <boost/thread/mutex.hpp>
#include <boost/thread/locks.hpp>
#include <pcl/correspondence.h>
#include <pcl/point_cloud.h>
#include <pcl/common/common_headers.h>
#include <pcl/io/pcd_io.h>
#include <pcl/visualization/pcl_visualizer.h>
#include <image_transport/subscriber_filter.h>
#include <pcl_ros/point_cloud.h>
#include "opencv2/stitching/stitcher.hpp"
namespace enc=sensor_msgs::image_encodings;

/**
 * this class represent the C21_Node,
 * it subscribe to two camera/image topics and provide the 3D reconstruction service
 **/
class C21_Node{

public:

	/**
	 * constructor, initializes the ROS node, subscribe it to the given topics and instruct it to provide the service
	 * @param left_camera the left camera image topic
	 * @param right_camera the right camera image topic
	 */
	  C21_Node(std::string left_camera,std::string right_camera) :
		it_(nh_),
		//the purpose of the following 3 lines is to synchronize the data from the cameras using a message filter
		//more on filters and how to use them can be found on http://www.ros.org/wiki/message_filters
		left_image_sub_( it_, left_camera, 1 ),
		right_image_sub_( it_, right_camera, 1 ),
		sync( MySyncPolicy( 10 ), left_image_sub_, right_image_sub_ )
	  {
		leftpub = it_.advertise("C21/left_camera/image", 1);
		rightpub = it_.advertise("C21/right_camera/image", 1);
		//set compression data to png
		ROS_INFO("finished subscribing\n");
		sync.registerCallback( boost::bind( &C21_Node::callback, this, _1, _2 ) );  //Specifying what to do with the data

/*
 * the Q matrix
 *     1. 0. 0. -2.9615028381347656e+02
 *     0. 1. 0. -2.3373317337036133e+02
 *     0. 0. 0. 5.6446880931501073e+02
 *     0. 0. -1.1340974198400260e-01 4.1658568844268817e+00
 */
		  Q03 = -2.9615028381347656;
		  Q13 = -2.3373317337036133;
		  Q23 = 5.6446880931501073;
		  Q32 = -1.1340974198400260;
		  Q33 = 4.1658568844268817;
		_myMutex=new boost::mutex();

		pcl_service = nh_.advertiseService("C21", &C21_Node::proccess, this); //Specifying what to do when a reconstructed 3d scene is requested
		ROS_INFO("service on\n");
		boost::thread panorama(&C21_Node::publishPanorama,this);
	  }


	  /**
	   * The call back function executed when a service is requested
	   * it must return true in order to work properly
	   * @param req the request message, generated by the node requesting the service
	   * @param res the response message, generated by the service node when a service is requested
	   */
	  bool proccess(C21_VisionAndLidar::C21::Request  &req,
			C21_VisionAndLidar::C21::Response &res )
	  {
		  ROS_INFO("recived request, tying to fetch data\n");

		  //reading the data we gathered
		   cv::Mat img_rgb = cv::imread("rgb.ppm", CV_LOAD_IMAGE_COLOR);
		   cv::Mat img_disparity = cv::imread("disp.ppm", CV_LOAD_IMAGE_GRAYSCALE);

		   //generating a point cloud
			 pcl::PointCloud<pcl::PointXYZRGB>::Ptr point_cloud_ptr (new pcl::PointCloud<pcl::PointXYZRGB>);

			 double px, py, pz;
			 uchar pr, pg, pb;

			 for (int i = 0; i < img_rgb.rows; i++)
			 {
			   uchar* rgb_ptr = img_rgb.ptr<uchar>(i);
			   uchar* disp_ptr = img_disparity.ptr<uchar>(i);
			   for (int j = 0; j < img_rgb.cols; j++)
			   {
				 //Get 3D coordinates
				 uchar d = disp_ptr[j];
				 if ( d == 0 ) continue; //Discard bad pixels
				 double pw = -1.0 * static_cast<double>(d) * Q32 + Q33;
				 px = static_cast<double>(j) + Q03;
				 py = static_cast<double>(i) + Q13;
				 pz = Q23;

				 px = px/pw;
				 py = py/pw;
				 pz = pz/pw;

				 //Get RGB info
				 pb = rgb_ptr[3*j];
				 pg = rgb_ptr[3*j+1];
				 pr = rgb_ptr[3*j+2];

				 //Insert info into point cloud structure
				 pcl::PointXYZRGB point;
				 point.x = px;
				 point.y = py;
				 point.z = pz;
				 uint32_t rgb = (static_cast<uint32_t>(pr) << 16 |
						 static_cast<uint32_t>(pg) << 8 | static_cast<uint32_t>(pb));
				 point.rgb = *reinterpret_cast<float*>(&rgb);
				 point_cloud_ptr->points.push_back (point);
			   }
			 }
			 point_cloud_ptr->width = (int) point_cloud_ptr->points.size();
			 point_cloud_ptr->height = 1;

			 //converting the point cloud to a ROS message and saving it the response object
			 pcl::PointCloud<pcl::PointXYZRGB> ans(*point_cloud_ptr);
			 pcl::toROSMsg<pcl::PointXYZRGB>(ans,res.scene_full_resolution_msg.cloud);

		  return true;
	  }


	  /**
	   * The call back function executed when a data is available
	   * @param left_msg ROS mesage with image data from the left camera topic
	   * @param right_msg ROS mesage with image data from the right camera topic
	   */
	  void callback(const sensor_msgs::ImageConstPtr& left_msg,const sensor_msgs::ImageConstPtr& right_msg){
		 cv_bridge::CvImagePtr left;
		 cv_bridge::CvImagePtr right;
		try
		{
		  left = cv_bridge::toCvCopy(left_msg,enc::BAYER_BGGR8);
		  right =cv_bridge::toCvCopy(right_msg,enc::BAYER_BGGR8);
		}
		catch (cv_bridge::Exception& e)
		{
		  ROS_ERROR("cv_bridge exception: %s", e.what());
		  return;
		}

		// first, compress raw images and publish them
		//this is done using the compressed_image_transport package
		//more information can be found here:
		//http://www.ros.org/wiki/image_transport/Tutorials/ExaminingImagePublisherSubscriber#Changing_Transport-Specific_Behavior
		sensor_msgs::ImagePtr leftMsg=left->toImageMsg();
		sensor_msgs::ImagePtr rightMsg=right->toImageMsg();
		leftMsg->encoding=enc::BAYER_BGGR8;
		rightMsg->encoding=enc::BAYER_BGGR8;
		leftMsg->header=left_msg->header;
		rightMsg->header=right_msg->header;
		leftpub.publish(leftMsg);
		rightpub.publish(rightMsg);
		ros::spinOnce();

		_myMutex->lock();
		IplImage tosave=left->image;
		cvSaveImage("rgb.ppm",&tosave);

		IplImage tosave2=right->image;
		cvSaveImage("rgb2.ppm",&tosave2);
		_myMutex->unlock();
		//calculating disparity
		cv::Mat left_image;
		cv::Mat right_image;
		cv::cvtColor( left->image,left_image, CV_BayerBG2GRAY);
		cv::cvtColor( right->image,right_image, CV_BayerBG2GRAY);
		IplImage temp=left_image;
		IplImage temp2=right_image;
		CvMat *matf= cvCreateMat ( temp.height, temp.width, CV_16S);
		CvStereoBMState * state=cvCreateStereoBMState(CV_STEREO_BM_BASIC,64);
		cvFindStereoCorrespondenceBM(&temp,&temp2,matf,state);
		CvMat * disp_left_visual= cvCreateMat(temp.height, temp.width, CV_8U);
		cvConvertScale( matf, disp_left_visual, -16 );
		cvNormalize( matf, matf, 0, 256, CV_MINMAX, NULL );
		int i, j;
		uchar *ptr_dst;
		IplImage *cv_image_depth_aux = cvCreateImage (cvGetSize(&temp),IPL_DEPTH_8U, 3);
		for ( i = 0; i < matf->rows; i++)
		{
			ptr_dst = (uchar*)(cv_image_depth_aux->imageData + i*cv_image_depth_aux->widthStep);
			for ( j = 0; j < matf->cols; j++ )
			{
				ptr_dst[3*j] = (uchar)((short int*)(matf->data.ptr + matf->step*i))[j];
				ptr_dst[3*j+1] = (uchar)((short int*)(matf->data.ptr + matf->step*i))[j];
				ptr_dst[3*j+2] = (uchar)((short int*)(matf->data.ptr + matf->step*i))[j];
			}
		}

		cvSaveImage("disp.ppm",cv_image_depth_aux);
		cvReleaseMat(&matf);
		cvReleaseStereoBMState(&state);
		cvReleaseMat(&disp_left_visual);
		cvReleaseImage(&cv_image_depth_aux);
	  }

	  void publishPanorama(){
		  smallPanoramicPublisher = it_.advertise("C21/smallPanorama", 1);
		  ros::Rate loop_rate=ros::Rate(10);
		  while(ros::ok()){
			  std::vector<cv::Mat> imgs;
			  _myMutex->lock();
			  imgs.push_back(cv::imread("rgb.ppm", CV_LOAD_IMAGE_COLOR));
			  imgs.push_back(cv::imread("rgb2.ppm", CV_LOAD_IMAGE_COLOR));
			  cv::Mat pano;
			  cv::Stitcher stitcher = cv::Stitcher::createDefault(false);
			  stitcher.stitch(imgs, pano);
 			  _myMutex->unlock();
	            cv_bridge::CvImage cvi;
	            cvi.header.stamp = ros::Time::now();
	            cvi.header.frame_id = "image";
	            cvi.encoding = "rgb8";
	            cvi.image = pano;

	            sensor_msgs::Image im;
	            cvi.toImageMsg(im);
			  smallPanoramicPublisher.publish(im);
			  loop_rate.sleep();
		  }
	  }
private:
  ros::NodeHandle nh_;
  image_transport::ImageTransport it_;
  cv::Mat Q;
  int counter;
  bool request;
  boost::mutex * _myMutex;
  typedef image_transport::SubscriberFilter ImageSubscriber;
  pcl::PointCloud<pcl::PointXYZRGB>* my_answer;
  ImageSubscriber left_image_sub_;
  ImageSubscriber right_image_sub_;
  image_transport::Publisher leftpub;
  image_transport::Publisher rightpub;
  image_transport::Publisher smallPanoramicPublisher;

  ros::ServiceServer pcl_service;
  typedef message_filters::sync_policies::ApproximateTime<
    sensor_msgs::Image, sensor_msgs::Image
  > MySyncPolicy;
  double Q03, Q13, Q23, Q32, Q33;
  message_filters::Synchronizer< MySyncPolicy > sync;
};

int main(int argc, char **argv)
{
  ros::init(argc, argv, "c21_Vision_and_Lidar");
  ros::NodeHandle nh("~");
  std::string left;
  std::string right;
  nh.getParam("left", left);
  nh.getParam("right", right);

  C21_Node my_node(left,right);
  while(ros::ok()){
	  ros::spin();
  }
  return 0;
}

